{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, RobertaTokenizer,AutoTokenizer, AutoModelForMaskedLM,AutoModel \n",
    "import torch\n",
    "\n",
    "model_name = 'DeepChem/ChemBERTa-77M-MLM'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "\n",
    "def get_bert_embeddings(smiles_strings):\n",
    "    encoded_input = tokenizer(smiles_strings, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]  # Using the [CLS] token embedding from last hidden state\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_strings = [\"C1CCCCC1\", \"C1=CC=CC=C1\"]\n",
    "embeddings = get_bert_embeddings(smiles_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('/home/parsa/smiles_classification/training_w_features.csv').sample(frac=1)\n",
    "# val_data = pd.read_csv('/home/parsa/smiles_classification/validation_w_features.csv').sample(frac=1)\n",
    "val_data = pd.read_csv('/home/parsa/smiles_classification/Features+ SMILES.csv').rename({'RESULTS':'RESULT'},axis=1) #pd.read_csv('/home/parsa/smiles_classification/data_validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>LogP</th>\n",
       "      <th>Number of Atoms</th>\n",
       "      <th>Number of Bonds</th>\n",
       "      <th>Number of Rings</th>\n",
       "      <th>Rotatable Bonds Count</th>\n",
       "      <th>Hydrogen Bond Donors</th>\n",
       "      <th>Hydrogen Bond Acceptors</th>\n",
       "      <th>Number of Stereocenters</th>\n",
       "      <th>Topological Polar Surface Area (TPSA)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Results</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SMILES  Molecular Weight  LogP  Number of Atoms  Number of Bonds  \\\n",
       "Results                                                                     \n",
       "0           203               203   203              203              203   \n",
       "1           203               203   203              203              203   \n",
       "\n",
       "         Number of Rings  Rotatable Bonds Count  Hydrogen Bond Donors  \\\n",
       "Results                                                                 \n",
       "0                    203                    203                   203   \n",
       "1                    203                    203                   203   \n",
       "\n",
       "         Hydrogen Bond Acceptors  Number of Stereocenters  \\\n",
       "Results                                                     \n",
       "0                            203                      203   \n",
       "1                            203                      203   \n",
       "\n",
       "         Topological Polar Surface Area (TPSA)  \n",
       "Results                                         \n",
       "0                                          203  \n",
       "1                                          203  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Results').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68        25\n",
      "           1       0.68      0.60      0.64        25\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.66      0.66      0.66        50\n",
      "weighted avg       0.66      0.66      0.66        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = SVC()\n",
    "\n",
    "embeddings = get_bert_embeddings(train_data.SMILES.tolist()) \n",
    "\n",
    "\n",
    "clf.fit(embeddings.numpy() , train_data.Results)\n",
    "\n",
    "val_embeddings = get_bert_embeddings(val_data.SMILES.tolist())\n",
    "\n",
    "y_pred = clf.predict(val_embeddings.numpy())\n",
    "print(classification_report(val_data.RESULT, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def process_X_data(smiles, features):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    embeddings = get_bert_embeddings(smiles).numpy()\n",
    "    combined_features = np.concatenate((embeddings, features), axis=1)\n",
    "    return scaler.fit_transform(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.25      0.40        12\n",
      "\n",
      "    accuracy                           0.25        12\n",
      "   macro avg       0.50      0.12      0.20        12\n",
      "weighted avg       1.00      0.25      0.40        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "feature_columns = ['Molecular Weight', 'LogP', 'Number of Atoms',\n",
    "       'Number of Bonds', 'Number of Rings', 'Rotatable Bonds Count',\n",
    "       'Hydrogen Bond Donors', 'Hydrogen Bond Acceptors',\n",
    "       'Number of Stereocenters', 'Topological Polar Surface Area (TPSA)'] # Add all your feature column names\n",
    "\n",
    "\n",
    "train_x = process_X_data(train_data.SMILES.tolist(), train_data[feature_columns].values ) \n",
    "clf.fit(train_x , train_data.Results)\n",
    "\n",
    "val_x = process_X_data(val_data.SMILES.tolist(), val_data[feature_columns].values ) \n",
    "y_pred = clf.predict(val_x)\n",
    "\n",
    "print(classification_report(val_data.RESULT, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "60 fits failed out of a total of 580.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 215, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Precomputed matrix must be a square matrix. Input is a 365x394 matrix.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 215, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Precomputed matrix must be a square matrix. Input is a 366x394 matrix.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/naive_bayes.py\", line 759, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/naive_bayes.py\", line 881, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1650, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.64054878 0.5320122  0.52006098 0.5320122  0.54914634        nan\n",
      " 0.59134146 0.62823171 0.61829268 0.62823171 0.64542683        nan\n",
      " 0.59853659 0.63817073 0.63817073 0.63817073 0.59140244        nan\n",
      " 0.59579268 0.62079268 0.62823171 0.56621951 0.59591463 0.60835366\n",
      " 0.71664634 0.70682927 0.70689024 0.69957317 0.6995122  0.67963415\n",
      " 0.6625     0.65804878 0.68743902 0.62560976 0.60609756 0.60097561\n",
      " 0.59323171 0.59085366 0.58621951 0.58365854 0.57871951 0.57158537\n",
      " 0.5979878  0.60317073 0.6179878  0.60073171 0.61810976 0.59323171\n",
      " 0.63512195 0.62542683 0.63506098 0.64731707 0.63756098 0.63768293\n",
      " 0.55896341        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.91570926 0.61406468 0.62336178 0.61406468 0.6081039         nan\n",
      " 0.9827547  0.82621603 0.85194625 0.82621603 0.70387754        nan\n",
      " 1.         0.95785313 0.94827532 0.95785313 0.6102882         nan\n",
      " 0.98248222 1.         1.         0.98221049 1.         1.\n",
      " 0.82676248 0.84592484 0.88123213 0.98932555 1.         1.\n",
      " 1.         1.         1.         0.88040796 0.96469421 0.99972603\n",
      " 0.78297702 0.72003294 0.70498241 0.68089827 0.66695262 0.66721611\n",
      " 1.         0.96415076 0.98686429 0.95785388 1.         0.96797964\n",
      " 1.         0.97755895 0.98494498 0.96606183 1.         0.97536941\n",
      " 0.66502807        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.67       0.46214286 0.61904762 0.46214286 0.65904762        nan\n",
      " 0.59642857 0.63119048 0.61119048 0.63119048 0.70571429        nan\n",
      " 0.59047619 0.63571429 0.63571429 0.63571429 0.63595238        nan\n",
      " 0.50714286 0.56142857 0.59619048 0.44238095 0.51666667 0.54714286\n",
      " 0.73452381 0.7102381  0.7052381  0.70071429 0.70452381 0.685\n",
      " 0.66547619 0.65619048 0.69071429 0.64071429 0.62119048 0.58619048\n",
      " 0.6252381  0.6347619  0.6302381  0.63452381 0.60071429 0.58190476\n",
      " 0.6247619  0.61       0.6252381  0.58619048 0.60095238 0.57095238\n",
      " 0.6597619  0.6302381  0.64       0.62571429 0.65       0.63047619\n",
      " 0.5902381         nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.93376869 0.56269141 0.68001862 0.56269141 0.717069          nan\n",
      " 0.99069237 0.8319552  0.86094397 0.8319552  0.74546028        nan\n",
      " 1.         0.96824596 0.96441782 0.96824596 0.64476971        nan\n",
      " 0.97098721 1.         1.         0.97374047 1.         1.\n",
      " 0.83962049 0.85330871 0.89383294 0.99671831 1.         1.\n",
      " 1.         1.         1.         0.89984687 0.9753648  1.\n",
      " 0.79966973 0.73836546 0.73394884 0.70933465 0.70059749 0.68251967\n",
      " 1.         0.94965472 0.99398607 0.95511319 1.         0.95950579\n",
      " 1.         0.9742689  0.984147   0.96004924 1.         0.96988831\n",
      " 0.71327989        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.64781072 0.44930006 0.48297935 0.44930006 0.58333008        nan\n",
      " 0.59273934 0.62888899 0.61596086 0.62888899 0.66414129        nan\n",
      " 0.59335511 0.63658468 0.63621766 0.63658468 0.6088721         nan\n",
      " 0.55283797 0.59456134 0.61388904 0.50002211 0.55724487 0.57999425\n",
      " 0.71995441 0.70580883 0.70495759 0.69692117 0.69849439 0.6793734\n",
      " 0.66199723 0.65680225 0.68689551 0.62841144 0.61029329 0.59289908\n",
      " 0.59951141 0.60624676 0.60269487 0.60369334 0.58771425 0.57440441\n",
      " 0.60621606 0.60245011 0.61896199 0.59315171 0.60945312 0.58074611\n",
      " 0.64168315 0.62563482 0.63469079 0.63765161 0.64121905 0.63130236\n",
      " 0.56394619        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.91719938 0.5601305  0.57986288 0.5601305  0.64482666        nan\n",
      " 0.9828972  0.82712842 0.85301738 0.82712842 0.71572659        nan\n",
      " 1.         0.95827604 0.94910532 0.95827604 0.6232029         nan\n",
      " 0.98225707 1.         1.         0.9820598  1.         1.\n",
      " 0.82898143 0.84704009 0.88262839 0.98940878 1.         1.\n",
      " 1.         1.         1.         0.88271284 0.9650722  0.99972752\n",
      " 0.78655753 0.72496853 0.71314116 0.68957902 0.67759828 0.67221713\n",
      " 1.         0.96359327 0.98700299 0.95781682 1.         0.96769998\n",
      " 1.         0.9774695  0.98486394 0.96573828 1.         0.97519059\n",
      " 0.67975823        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.63943819 0.61091724 0.47746276 0.61091724 0.53748995        nan\n",
      " 0.59752965 0.63463675 0.62534726 0.63463675 0.63865253        nan\n",
      " 0.60396454 0.6437517  0.64187757 0.6437517  0.59106852        nan\n",
      " 0.6162657  0.65005678 0.64004343 0.58769841 0.61873901 0.63128205\n",
      " 0.71399819 0.71074371 0.71478089 0.70096107 0.69697604 0.67942629\n",
      " 0.66200708 0.66108952 0.68747589 0.63059795 0.60960014 0.60747363\n",
      " 0.58469978 0.58268831 0.57933105 0.57657162 0.57641205 0.57160136\n",
      " 0.59379929 0.6036104  0.6168133  0.60526149 0.62454613 0.59964598\n",
      " 0.63085728 0.62548517 0.63557524 0.66070441 0.63606124 0.64053123\n",
      " 0.55134902        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.90132294 0.66369165 0.72219209 0.66369165 0.59028107        nan\n",
      " 0.97524198 0.82274067 0.84608902 0.82274067 0.68839005        nan\n",
      " 1.         0.94854112 0.93430578 0.94854112 0.60318821        nan\n",
      " 0.99386016 1.         1.         0.99057643 1.         1.\n",
      " 0.81890148 0.84109471 0.87198168 0.98223457 1.         1.\n",
      " 1.         1.         1.         0.8663003  0.95509372 0.99945652\n",
      " 0.77397972 0.71218656 0.69384622 0.67123964 0.65639651 0.66233989\n",
      " 1.         0.97803507 0.98019056 0.96082075 1.         0.97613806\n",
      " 1.         0.98081306 0.98608417 0.9718808  1.         0.98079269\n",
      " 0.65010179        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier': GradientBoostingClassifier(), 'classifier__learning_rate': 0.01, 'classifier__n_estimators': 150}\n",
      "Best cross-validated score: 0.7147808916229967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB  # Gaussian for continuous features, Multinomial for discrete\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "\n",
    "# Define a pipeline if scaling is needed (e.g., for SVM or KNN)\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Define parameter grids for different classifiers\n",
    "param_grid = [\n",
    "    {'classifier': [SVC()],\n",
    "     'scaler': [StandardScaler()],\n",
    "     'classifier__C': [0.1, 1, 10],\n",
    "     'classifier__kernel': ['linear', 'rbf', 'poly', 'rbf', 'sigmoid', 'precomputed']},\n",
    "    {'classifier': [RandomForestClassifier()],\n",
    "     'classifier__n_estimators': [10, 50, 100],\n",
    "     'classifier__max_features': ['sqrt', 'log2']},\n",
    "    {'classifier': [GradientBoostingClassifier()],\n",
    "     'classifier__n_estimators': [50, 100, 150],\n",
    "     'classifier__learning_rate': [0.01, 0.1, 0.2]},\n",
    "    {'classifier': [LogisticRegression()],\n",
    "     'scaler': [StandardScaler()],\n",
    "     'classifier__C': [0.1, 1, 10]},\n",
    "    {'classifier': [KNeighborsClassifier()],\n",
    "     'scaler': [StandardScaler()],\n",
    "     'classifier__n_neighbors': [3, 5, 7, 9, 11, 13]},\n",
    "     {\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__criterion': ['gini', 'entropy'],  # 'entropy' is used for the Information Gain in C4.5\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 10]\n",
    "    },\n",
    "    {\n",
    "        'classifier': [GaussianNB()]  # No hyperparameters for tuning typically\n",
    "    },\n",
    "    {\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.1, 1.0, 10.0]  # Smoothing parameter\n",
    "    }\n",
    "]\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'precision': make_scorer(precision_score)  # Default is binary; adjust as needed\n",
    "}\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid, \n",
    "    scoring=scoring, \n",
    "    refit='precision',  # Choose one metric to use for refitting the best model\n",
    "    cv=10, \n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Assuming X_train, y_train are your data prepared earlier\n",
    "grid_search.fit(train_x,  train_data.Results)\n",
    "\n",
    "# Best model after grid search\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>rank_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.714781</td>\n",
       "      <td>0.706890</td>\n",
       "      <td>0.705238</td>\n",
       "      <td>0.704958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.660704</td>\n",
       "      <td>0.647317</td>\n",
       "      <td>0.625714</td>\n",
       "      <td>0.637652</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.650057</td>\n",
       "      <td>0.620793</td>\n",
       "      <td>0.561429</td>\n",
       "      <td>0.594561</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.643752</td>\n",
       "      <td>0.638171</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.636585</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.630598</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.640714</td>\n",
       "      <td>0.628411</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.584700</td>\n",
       "      <td>0.593232</td>\n",
       "      <td>0.625238</td>\n",
       "      <td>0.599511</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.551349</td>\n",
       "      <td>0.558963</td>\n",
       "      <td>0.590238</td>\n",
       "      <td>0.563946</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param_classifier  mean_test_precision  mean_test_accuracy  \\\n",
       "26  GradientBoostingClassifier()             0.714781            0.706890   \n",
       "51      DecisionTreeClassifier()             0.660704            0.647317   \n",
       "19      RandomForestClassifier()             0.650057            0.620793   \n",
       "13                         SVC()             0.643752            0.638171   \n",
       "33          LogisticRegression()             0.630598            0.625610   \n",
       "36        KNeighborsClassifier()             0.584700            0.593232   \n",
       "54                  GaussianNB()             0.551349            0.558963   \n",
       "55               MultinomialNB()                  NaN                 NaN   \n",
       "\n",
       "    mean_test_recall  mean_test_f1  rank_test_precision  \n",
       "26          0.705238      0.704958                    1  \n",
       "51          0.625714      0.637652                   10  \n",
       "19          0.561429      0.594561                   11  \n",
       "13          0.635714      0.636585                   12  \n",
       "33          0.640714      0.628411                   25  \n",
       "36          0.625238      0.599511                   44  \n",
       "54          0.590238      0.563946                   50  \n",
       "55               NaN           NaN                   53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = grid_search.cv_results_\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert results to a DataFrame for easier handling and visualization\n",
    "df_results = pd.DataFrame(results)\n",
    "# selected_columns = [col for col in df_results.columns if 'param_' in col or 'test_accuracy' in col or 'test_precision' in col]\n",
    "# df_results = df_results[selected_columns]\n",
    "display(df_results[['param_classifier','mean_test_precision',\t'mean_test_accuracy','mean_test_recall',\t'mean_test_f1',\t'rank_test_precision']].sort_values('rank_test_precision').drop_duplicates('param_classifier'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>rank_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.715444</td>\n",
       "      <td>0.714268</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.709894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.653751</td>\n",
       "      <td>0.652439</td>\n",
       "      <td>0.666429</td>\n",
       "      <td>0.653442</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.651269</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.700476</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.650541</td>\n",
       "      <td>0.653171</td>\n",
       "      <td>0.660476</td>\n",
       "      <td>0.653065</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.645208</td>\n",
       "      <td>0.630793</td>\n",
       "      <td>0.588333</td>\n",
       "      <td>0.607606</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.593355</td>\n",
       "      <td>0.603598</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.608922</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.581815</td>\n",
       "      <td>0.586220</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.609790</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param_classifier  mean_test_precision  mean_test_accuracy  \\\n",
       "24  GradientBoostingClassifier()             0.715444            0.714268   \n",
       "33          LogisticRegression()             0.653751            0.652439   \n",
       "10                         SVC()             0.651269            0.662500   \n",
       "50      DecisionTreeClassifier()             0.650541            0.653171   \n",
       "23      RandomForestClassifier()             0.645208            0.630793   \n",
       "38        KNeighborsClassifier()             0.593355            0.603598   \n",
       "54                  GaussianNB()             0.581815            0.586220   \n",
       "55               MultinomialNB()                  NaN                 NaN   \n",
       "\n",
       "    mean_test_recall  mean_test_f1  rank_test_precision  \n",
       "24          0.710714      0.709894                    1  \n",
       "33          0.666429      0.653442                    9  \n",
       "10          0.700476      0.670096                   11  \n",
       "50          0.660476      0.653065                   12  \n",
       "23          0.588333      0.607606                   13  \n",
       "38          0.636905      0.608922                   37  \n",
       "54          0.651429      0.609790                   40  \n",
       "55               NaN           NaN                   53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = grid_search.cv_results_\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert results to a DataFrame for easier handling and visualization\n",
    "df_results = pd.DataFrame(results)\n",
    "# selected_columns = [col for col in df_results.columns if 'param_' in col or 'test_accuracy' in col or 'test_precision' in col]\n",
    "# df_results = df_results[selected_columns]\n",
    "display(df_results[['param_classifier','mean_test_precision',\t'mean_test_accuracy','mean_test_recall',\t'mean_test_f1',\t'rank_test_precision']].sort_values('rank_test_precision').drop_duplicates('param_classifier'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>rank_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.720489</td>\n",
       "      <td>0.707012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.711206</td>\n",
       "      <td>0.704512</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.705187</td>\n",
       "      <td>0.697134</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.672683</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.670787</td>\n",
       "      <td>0.672378</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.665368</td>\n",
       "      <td>0.655366</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.658973</td>\n",
       "      <td>0.655427</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.655579</td>\n",
       "      <td>0.631098</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.652968</td>\n",
       "      <td>0.645488</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.650698</td>\n",
       "      <td>0.645183</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.647874</td>\n",
       "      <td>0.640427</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.647133</td>\n",
       "      <td>0.645366</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.644332</td>\n",
       "      <td>0.635122</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.641313</td>\n",
       "      <td>0.635732</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.641241</td>\n",
       "      <td>0.637744</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.640121</td>\n",
       "      <td>0.635427</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.640121</td>\n",
       "      <td>0.635427</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.637262</td>\n",
       "      <td>0.630549</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.630519</td>\n",
       "      <td>0.622988</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.630516</td>\n",
       "      <td>0.635427</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.627886</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.626499</td>\n",
       "      <td>0.622866</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.626162</td>\n",
       "      <td>0.613415</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.624132</td>\n",
       "      <td>0.598902</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.623414</td>\n",
       "      <td>0.610854</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.623414</td>\n",
       "      <td>0.610854</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.623222</td>\n",
       "      <td>0.612744</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.622865</td>\n",
       "      <td>0.615793</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.619437</td>\n",
       "      <td>0.620427</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.615246</td>\n",
       "      <td>0.615732</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.612323</td>\n",
       "      <td>0.622744</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.608826</td>\n",
       "      <td>0.607988</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.608290</td>\n",
       "      <td>0.579329</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.607869</td>\n",
       "      <td>0.610610</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.607113</td>\n",
       "      <td>0.595854</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.605044</td>\n",
       "      <td>0.588720</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>0.595671</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.603378</td>\n",
       "      <td>0.593659</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.600894</td>\n",
       "      <td>0.588537</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.593691</td>\n",
       "      <td>0.589085</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.591411</td>\n",
       "      <td>0.578841</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.589348</td>\n",
       "      <td>0.522683</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.589348</td>\n",
       "      <td>0.522683</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.588713</td>\n",
       "      <td>0.583537</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.582824</td>\n",
       "      <td>0.586341</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.573050</td>\n",
       "      <td>0.574024</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.571322</td>\n",
       "      <td>0.576341</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.563066</td>\n",
       "      <td>0.566707</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.558590</td>\n",
       "      <td>0.558841</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.557683</td>\n",
       "      <td>0.551890</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.551736</td>\n",
       "      <td>0.549024</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.530875</td>\n",
       "      <td>0.497744</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param_classifier  mean_test_precision  mean_test_accuracy  \\\n",
       "25  GradientBoostingClassifier()             0.720489            0.707012   \n",
       "24  GradientBoostingClassifier()             0.711206            0.704512   \n",
       "26  GradientBoostingClassifier()             0.705187            0.697134   \n",
       "27  GradientBoostingClassifier()             0.672727            0.672683   \n",
       "10                         SVC()             0.670787            0.672378   \n",
       "28  GradientBoostingClassifier()             0.665368            0.655366   \n",
       "29  GradientBoostingClassifier()             0.658973            0.655427   \n",
       "18      RandomForestClassifier()             0.655579            0.631098   \n",
       "32  GradientBoostingClassifier()             0.652968            0.645488   \n",
       "42      DecisionTreeClassifier()             0.650698            0.645183   \n",
       "46      DecisionTreeClassifier()             0.647874            0.640427   \n",
       "44      DecisionTreeClassifier()             0.647133            0.645366   \n",
       "0                          SVC()             0.644332            0.635122   \n",
       "30  GradientBoostingClassifier()             0.641313            0.635732   \n",
       "47      DecisionTreeClassifier()             0.641241            0.637744   \n",
       "13                         SVC()             0.640121            0.635427   \n",
       "15                         SVC()             0.640121            0.635427   \n",
       "33          LogisticRegression()             0.637262            0.630549   \n",
       "52      DecisionTreeClassifier()             0.630519            0.622988   \n",
       "45      DecisionTreeClassifier()             0.630516            0.635427   \n",
       "31  GradientBoostingClassifier()             0.627886            0.625610   \n",
       "43      DecisionTreeClassifier()             0.626499            0.622866   \n",
       "14                         SVC()             0.626162            0.613415   \n",
       "19      RandomForestClassifier()             0.624132            0.598902   \n",
       "9                          SVC()             0.623414            0.610854   \n",
       "7                          SVC()             0.623414            0.610854   \n",
       "50      DecisionTreeClassifier()             0.623222            0.612744   \n",
       "20      RandomForestClassifier()             0.622865            0.615793   \n",
       "49      DecisionTreeClassifier()             0.619437            0.620427   \n",
       "48      DecisionTreeClassifier()             0.615246            0.615732   \n",
       "16                         SVC()             0.612323            0.622744   \n",
       "53      DecisionTreeClassifier()             0.608826            0.607988   \n",
       "21      RandomForestClassifier()             0.608290            0.579329   \n",
       "51      DecisionTreeClassifier()             0.607869            0.610610   \n",
       "35          LogisticRegression()             0.607113            0.595854   \n",
       "6                          SVC()             0.605044            0.588720   \n",
       "34          LogisticRegression()             0.604667            0.595671   \n",
       "8                          SVC()             0.603378            0.593659   \n",
       "12                         SVC()             0.600894            0.588537   \n",
       "23      RandomForestClassifier()             0.593691            0.589085   \n",
       "22      RandomForestClassifier()             0.591411            0.578841   \n",
       "3                          SVC()             0.589348            0.522683   \n",
       "1                          SVC()             0.589348            0.522683   \n",
       "40        KNeighborsClassifier()             0.588713            0.583537   \n",
       "38        KNeighborsClassifier()             0.582824            0.586341   \n",
       "36        KNeighborsClassifier()             0.573050            0.574024   \n",
       "39        KNeighborsClassifier()             0.571322            0.576341   \n",
       "54                  GaussianNB()             0.563066            0.566707   \n",
       "37        KNeighborsClassifier()             0.558590            0.558841   \n",
       "4                          SVC()             0.557683            0.551890   \n",
       "41        KNeighborsClassifier()             0.551736            0.549024   \n",
       "2                          SVC()             0.530875            0.497744   \n",
       "5                          SVC()                  NaN                 NaN   \n",
       "56               MultinomialNB()                  NaN                 NaN   \n",
       "11                         SVC()                  NaN                 NaN   \n",
       "17                         SVC()                  NaN                 NaN   \n",
       "55               MultinomialNB()                  NaN                 NaN   \n",
       "57               MultinomialNB()                  NaN                 NaN   \n",
       "\n",
       "    rank_test_precision  \n",
       "25                    1  \n",
       "24                    2  \n",
       "26                    3  \n",
       "27                    4  \n",
       "10                    5  \n",
       "28                    6  \n",
       "29                    7  \n",
       "18                    8  \n",
       "32                    9  \n",
       "42                   10  \n",
       "46                   11  \n",
       "44                   12  \n",
       "0                    13  \n",
       "30                   14  \n",
       "47                   15  \n",
       "13                   16  \n",
       "15                   16  \n",
       "33                   18  \n",
       "52                   19  \n",
       "45                   20  \n",
       "31                   21  \n",
       "43                   22  \n",
       "14                   23  \n",
       "19                   24  \n",
       "9                    25  \n",
       "7                    25  \n",
       "50                   27  \n",
       "20                   28  \n",
       "49                   29  \n",
       "48                   30  \n",
       "16                   31  \n",
       "53                   32  \n",
       "21                   33  \n",
       "51                   34  \n",
       "35                   35  \n",
       "6                    36  \n",
       "34                   37  \n",
       "8                    38  \n",
       "12                   39  \n",
       "23                   40  \n",
       "22                   41  \n",
       "3                    42  \n",
       "1                    42  \n",
       "40                   44  \n",
       "38                   45  \n",
       "36                   46  \n",
       "39                   47  \n",
       "54                   48  \n",
       "37                   49  \n",
       "4                    50  \n",
       "41                   51  \n",
       "2                    52  \n",
       "5                    53  \n",
       "56                   53  \n",
       "11                   53  \n",
       "17                   53  \n",
       "55                   53  \n",
       "57                   53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = grid_search.cv_results_\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert results to a DataFrame for easier handling and visualization\n",
    "df_results = pd.DataFrame(results)\n",
    "selected_columns = [col for col in df_results.columns if 'param_' in col or 'test_accuracy' in col or 'test_precision' in col]\n",
    "df_results = df_results[selected_columns]\n",
    "display(df_results[['param_classifier','mean_test_precision',\t'mean_test_accuracy',\t'rank_test_precision']].sort_values('rank_test_precision'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_classifier</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>rank_test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.633377</td>\n",
       "      <td>0.072645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.083826</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.616650</td>\n",
       "      <td>0.056337</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.616093</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.614168</td>\n",
       "      <td>0.046784</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.612085</td>\n",
       "      <td>0.073829</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.612085</td>\n",
       "      <td>0.073829</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.609768</td>\n",
       "      <td>0.057518</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.609615</td>\n",
       "      <td>0.196425</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.605718</td>\n",
       "      <td>0.052138</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.604214</td>\n",
       "      <td>0.040125</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.603325</td>\n",
       "      <td>0.068530</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.599987</td>\n",
       "      <td>0.043306</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.599987</td>\n",
       "      <td>0.043306</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.599050</td>\n",
       "      <td>0.057961</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.596342</td>\n",
       "      <td>0.055177</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.595863</td>\n",
       "      <td>0.049047</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.595667</td>\n",
       "      <td>0.025321</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.595560</td>\n",
       "      <td>0.083424</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.592832</td>\n",
       "      <td>0.033712</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.591552</td>\n",
       "      <td>0.041855</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.590418</td>\n",
       "      <td>0.054429</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.580513</td>\n",
       "      <td>0.040187</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.579863</td>\n",
       "      <td>0.052663</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>0.073797</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.577857</td>\n",
       "      <td>0.090023</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.577547</td>\n",
       "      <td>0.056829</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.577118</td>\n",
       "      <td>0.042118</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.575150</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.569428</td>\n",
       "      <td>0.066856</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.566639</td>\n",
       "      <td>0.045993</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.564345</td>\n",
       "      <td>0.071164</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.562455</td>\n",
       "      <td>0.035967</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.561853</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.551525</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.546644</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.545253</td>\n",
       "      <td>0.070409</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.542949</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.542418</td>\n",
       "      <td>0.041370</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.541447</td>\n",
       "      <td>0.055284</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.541283</td>\n",
       "      <td>0.032145</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.540411</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.538390</td>\n",
       "      <td>0.033586</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.537393</td>\n",
       "      <td>0.072749</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.535068</td>\n",
       "      <td>0.035656</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.534920</td>\n",
       "      <td>0.054550</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.529367</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.528831</td>\n",
       "      <td>0.035048</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.512129</td>\n",
       "      <td>0.033471</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.431579</td>\n",
       "      <td>0.225587</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.418139</td>\n",
       "      <td>0.214564</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.418139</td>\n",
       "      <td>0.214564</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                param_classifier  mean_test_precision  std_test_precision  \\\n",
       "33          LogisticRegression()             0.633377            0.072645   \n",
       "18      RandomForestClassifier()             0.619565            0.083826   \n",
       "0                          SVC()             0.616650            0.056337   \n",
       "8                          SVC()             0.616093            0.070229   \n",
       "14                         SVC()             0.614168            0.046784   \n",
       "15                         SVC()             0.612085            0.073829   \n",
       "13                         SVC()             0.612085            0.073829   \n",
       "32  GradientBoostingClassifier()             0.609768            0.057518   \n",
       "4                          SVC()             0.609615            0.196425   \n",
       "10                         SVC()             0.605718            0.052138   \n",
       "27  GradientBoostingClassifier()             0.604214            0.040125   \n",
       "34          LogisticRegression()             0.603325            0.068530   \n",
       "7                          SVC()             0.599987            0.043306   \n",
       "9                          SVC()             0.599987            0.043306   \n",
       "29  GradientBoostingClassifier()             0.599050            0.057961   \n",
       "28  GradientBoostingClassifier()             0.596342            0.055177   \n",
       "36        KNeighborsClassifier()             0.595863            0.049047   \n",
       "31  GradientBoostingClassifier()             0.595667            0.025321   \n",
       "22      RandomForestClassifier()             0.595560            0.083424   \n",
       "23      RandomForestClassifier()             0.592832            0.033712   \n",
       "20      RandomForestClassifier()             0.591552            0.041855   \n",
       "30  GradientBoostingClassifier()             0.590418            0.054429   \n",
       "19      RandomForestClassifier()             0.580513            0.040187   \n",
       "12                         SVC()             0.579863            0.052663   \n",
       "35          LogisticRegression()             0.579167            0.073797   \n",
       "38        KNeighborsClassifier()             0.577857            0.090023   \n",
       "6                          SVC()             0.577547            0.056829   \n",
       "16                         SVC()             0.577118            0.042118   \n",
       "49      DecisionTreeClassifier()             0.575150            0.028352   \n",
       "25  GradientBoostingClassifier()             0.569428            0.066856   \n",
       "26  GradientBoostingClassifier()             0.566639            0.045993   \n",
       "21      RandomForestClassifier()             0.564345            0.071164   \n",
       "24  GradientBoostingClassifier()             0.562455            0.035967   \n",
       "37        KNeighborsClassifier()             0.561853            0.097575   \n",
       "40        KNeighborsClassifier()             0.551525            0.085833   \n",
       "46      DecisionTreeClassifier()             0.546644            0.029275   \n",
       "39        KNeighborsClassifier()             0.545253            0.070409   \n",
       "48      DecisionTreeClassifier()             0.542949            0.025449   \n",
       "45      DecisionTreeClassifier()             0.542418            0.041370   \n",
       "51      DecisionTreeClassifier()             0.541447            0.055284   \n",
       "54                  GaussianNB()             0.541283            0.032145   \n",
       "52      DecisionTreeClassifier()             0.540411            0.033147   \n",
       "53      DecisionTreeClassifier()             0.538390            0.033586   \n",
       "41        KNeighborsClassifier()             0.537393            0.072749   \n",
       "50      DecisionTreeClassifier()             0.535068            0.035656   \n",
       "43      DecisionTreeClassifier()             0.534920            0.054550   \n",
       "44      DecisionTreeClassifier()             0.529367            0.028186   \n",
       "47      DecisionTreeClassifier()             0.528831            0.035048   \n",
       "42      DecisionTreeClassifier()             0.512129            0.033471   \n",
       "2                          SVC()             0.431579            0.225587   \n",
       "1                          SVC()             0.418139            0.214564   \n",
       "3                          SVC()             0.418139            0.214564   \n",
       "55               MultinomialNB()                  NaN                 NaN   \n",
       "56               MultinomialNB()                  NaN                 NaN   \n",
       "11                         SVC()                  NaN                 NaN   \n",
       "5                          SVC()                  NaN                 NaN   \n",
       "17                         SVC()                  NaN                 NaN   \n",
       "57               MultinomialNB()                  NaN                 NaN   \n",
       "\n",
       "    rank_test_precision  \n",
       "33                    1  \n",
       "18                    2  \n",
       "0                     3  \n",
       "8                     4  \n",
       "14                    5  \n",
       "15                    6  \n",
       "13                    6  \n",
       "32                    8  \n",
       "4                     9  \n",
       "10                   10  \n",
       "27                   11  \n",
       "34                   12  \n",
       "7                    13  \n",
       "9                    13  \n",
       "29                   15  \n",
       "28                   16  \n",
       "36                   17  \n",
       "31                   18  \n",
       "22                   19  \n",
       "23                   20  \n",
       "20                   21  \n",
       "30                   22  \n",
       "19                   23  \n",
       "12                   24  \n",
       "35                   25  \n",
       "38                   26  \n",
       "6                    27  \n",
       "16                   28  \n",
       "49                   29  \n",
       "25                   30  \n",
       "26                   31  \n",
       "21                   32  \n",
       "24                   33  \n",
       "37                   34  \n",
       "40                   35  \n",
       "46                   36  \n",
       "39                   37  \n",
       "48                   38  \n",
       "45                   39  \n",
       "51                   40  \n",
       "54                   41  \n",
       "52                   42  \n",
       "53                   43  \n",
       "41                   44  \n",
       "50                   45  \n",
       "43                   46  \n",
       "44                   47  \n",
       "47                   48  \n",
       "42                   49  \n",
       "2                    50  \n",
       "1                    51  \n",
       "3                    51  \n",
       "55                   53  \n",
       "56                   53  \n",
       "11                   53  \n",
       "5                    53  \n",
       "17                   53  \n",
       "57                   53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the results for only smile embeddings\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert results to a DataFrame for easier handling and visualization\n",
    "df_results = pd.DataFrame(results)\n",
    "selected_columns = [col for col in df_results.columns if 'param_' in col or 'test_accuracy' in col or 'test_precision' in col]\n",
    "df_results = df_results[selected_columns]\n",
    "display(df_results[['param_classifier','mean_test_precision',\t'std_test_precision',\t'rank_test_precision']].sort_values('rank_test_precision'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        25\n",
      "           1       0.68      0.68      0.68        25\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.68      0.68      0.68        50\n",
      "weighted avg       0.68      0.68      0.68        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = grid_search.predict(val_x) \n",
    "# Print classification report\n",
    "print(classification_report(val_data.RESULT, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "AWS_ACCESS_KEY_ID = \"AKIA5KLWPDHXUMLAB6EO\"\n",
    "AWS_SECRET_ACCESS_KEY= \"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\"\n",
    "\n",
    "# model.trunk.set_chunk_size(64)\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "                     aws_access_key_id=AWS_ACCESS_KEY_ID, \n",
    "                      aws_secret_access_key=AWS_SECRET_ACCESS_KEY, \n",
    "                      \n",
    ")\n",
    "def upload_pdb_file(bucket, key, upload_path):\n",
    "    s3.upload_file(upload_path, bucket, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'model-server-data'\n",
    "upload_pdb_file(bucket_name, 'albert_pdb/vae_train.zip', '/data/parsa/AFDB/train.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
