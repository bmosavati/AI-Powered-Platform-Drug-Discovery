{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class ChemBERTaWithFeatures(nn.Module):\n",
    "    def __init__(self, chemberta_model_name, feature_dim):\n",
    "        super(ChemBERTaWithFeatures, self).__init__()\n",
    "        self.chemberta = AutoModel.from_pretrained(chemberta_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.feature_batch_norm = nn.BatchNorm1d(feature_dim)\n",
    "        self.classifier = nn.Linear(self.chemberta.config.hidden_size + feature_dim, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, features):\n",
    "        chemberta_output = self.chemberta(input_ids, attention_mask=attention_mask)\n",
    "        cls_output = chemberta_output.last_hidden_state[:, 0, :]\n",
    "        normalized_features = self.feature_batch_norm(features)\n",
    "        concatenated = torch.cat((cls_output, normalized_features), dim=1)\n",
    "        concatenated = self.dropout(concatenated)\n",
    "        logits = self.classifier(concatenated)\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        return probabilities\n",
    "\n",
    "# Dataset class\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, encodings, features, labels):\n",
    "        self.encodings = encodings\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['features'] = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "def compute_metrics(preds, labels):\n",
    "    preds = preds.round()  # Convert probabilities to binary predictions\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, zero_division=0)  # Avoid division by zero\n",
    "    return accuracy, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MLM and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parsa/conda/envs/p2/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6817942215846136, Train Accuracy: 0.5689655172413793, Train Precision: 0.5786516853932584\n",
      "Epoch 1: Val Loss: 0.6392378211021423, Val Accuracy: 0.6, Val Precision: 0.5925925925925926\n",
      "Epoch 2: Train Loss: 0.6751704720350412, Train Accuracy: 0.6059113300492611, Train Precision: 0.6069651741293532\n",
      "Epoch 2: Val Loss: 0.633136585354805, Val Accuracy: 0.62, Val Precision: 0.5882352941176471\n",
      "Epoch 3: Train Loss: 0.6578912093089178, Train Accuracy: 0.6379310344827587, Train Precision: 0.6458333333333334\n",
      "Epoch 3: Val Loss: 0.6219532191753387, Val Accuracy: 0.7, Val Precision: 0.6785714285714286\n",
      "Epoch 4: Train Loss: 0.6474480330944061, Train Accuracy: 0.6896551724137931, Train Precision: 0.6896551724137931\n",
      "Epoch 4: Val Loss: 0.6149758249521255, Val Accuracy: 0.7, Val Precision: 0.6666666666666666\n",
      "Epoch 5: Train Loss: 0.6289966610761789, Train Accuracy: 0.7044334975369458, Train Precision: 0.7004830917874396\n",
      "Epoch 5: Val Loss: 0.6069946885108948, Val Accuracy: 0.7, Val Precision: 0.6785714285714286\n",
      "Epoch 6: Train Loss: 0.6070109812112955, Train Accuracy: 0.7093596059113301, Train Precision: 0.7033492822966507\n",
      "Epoch 6: Val Loss: 0.611212283372879, Val Accuracy: 0.64, Val Precision: 0.6129032258064516\n",
      "Epoch 7: Train Loss: 0.5862097579699296, Train Accuracy: 0.7216748768472906, Train Precision: 0.725\n",
      "Epoch 7: Val Loss: 0.6311145722866058, Val Accuracy: 0.66, Val Precision: 0.625\n",
      "Epoch 8: Train Loss: 0.5737745681634316, Train Accuracy: 0.7339901477832512, Train Precision: 0.7074235807860262\n",
      "Epoch 8: Val Loss: 0.6340222805738449, Val Accuracy: 0.64, Val Precision: 0.6060606060606061\n",
      "Epoch 9: Train Loss: 0.5606286858136837, Train Accuracy: 0.7438423645320197, Train Precision: 0.728110599078341\n",
      "Epoch 9: Val Loss: 0.6199179589748383, Val Accuracy: 0.64, Val Precision: 0.6060606060606061\n",
      "Epoch 10: Train Loss: 0.5263562638026017, Train Accuracy: 0.7487684729064039, Train Precision: 0.730593607305936\n",
      "Epoch 10: Val Loss: 0.6376830041408539, Val Accuracy: 0.62, Val Precision: 0.5882352941176471\n",
      "Epoch 11: Train Loss: 0.5333616745013458, Train Accuracy: 0.7610837438423645, Train Precision: 0.7523809523809524\n",
      "Epoch 11: Val Loss: 0.7257493361830711, Val Accuracy: 0.58, Val Precision: 0.5526315789473685\n",
      "Epoch 12: Train Loss: 0.5217478344073663, Train Accuracy: 0.7536945812807881, Train Precision: 0.7172995780590717\n",
      "Epoch 12: Val Loss: 0.6822198182344437, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 13: Train Loss: 0.4928145053294989, Train Accuracy: 0.7832512315270936, Train Precision: 0.7649769585253456\n",
      "Epoch 13: Val Loss: 0.6806842088699341, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 14: Train Loss: 0.4818820655345917, Train Accuracy: 0.7758620689655172, Train Precision: 0.7545454545454545\n",
      "Epoch 14: Val Loss: 0.7142882347106934, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 15: Train Loss: 0.455066883793244, Train Accuracy: 0.8103448275862069, Train Precision: 0.8088235294117647\n",
      "Epoch 15: Val Loss: 0.6917549669742584, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 16: Train Loss: 0.43975659287892854, Train Accuracy: 0.8201970443349754, Train Precision: 0.7954545454545454\n",
      "Epoch 16: Val Loss: 0.7615930438041687, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 17: Train Loss: 0.4303966027039748, Train Accuracy: 0.8275862068965517, Train Precision: 0.8093023255813954\n",
      "Epoch 17: Val Loss: 0.681605689227581, Val Accuracy: 0.56, Val Precision: 0.5454545454545454\n",
      "Epoch 18: Train Loss: 0.41896098450972485, Train Accuracy: 0.8251231527093597, Train Precision: 0.8113207547169812\n",
      "Epoch 18: Val Loss: 0.802291750907898, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 19: Train Loss: 0.4136129892789401, Train Accuracy: 0.8448275862068966, Train Precision: 0.8240740740740741\n",
      "Epoch 19: Val Loss: 0.8569105267524719, Val Accuracy: 0.64, Val Precision: 0.5853658536585366\n",
      "Epoch 20: Train Loss: 0.4147849277808116, Train Accuracy: 0.8300492610837439, Train Precision: 0.8130841121495327\n",
      "Epoch 20: Val Loss: 0.7956829369068146, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 21: Train Loss: 0.37652625430088776, Train Accuracy: 0.8669950738916257, Train Precision: 0.8743718592964824\n",
      "Epoch 21: Val Loss: 0.817984014749527, Val Accuracy: 0.66, Val Precision: 0.6\n",
      "Epoch 22: Train Loss: 0.3290916165480247, Train Accuracy: 0.8990147783251231, Train Precision: 0.8857142857142857\n",
      "Epoch 22: Val Loss: 0.7748197391629219, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 23: Train Loss: 0.33111874759197235, Train Accuracy: 0.8793103448275862, Train Precision: 0.8666666666666667\n",
      "Epoch 23: Val Loss: 0.8765519186854362, Val Accuracy: 0.62, Val Precision: 0.575\n",
      "Epoch 24: Train Loss: 0.32465505599975586, Train Accuracy: 0.8817733990147784, Train Precision: 0.8708133971291866\n",
      "Epoch 24: Val Loss: 0.8359336629509926, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 25: Train Loss: 0.2716796197570287, Train Accuracy: 0.9211822660098522, Train Precision: 0.9253731343283582\n",
      "Epoch 25: Val Loss: 0.7488294467329979, Val Accuracy: 0.62, Val Precision: 0.5789473684210527\n",
      "Epoch 26: Train Loss: 0.274051638176808, Train Accuracy: 0.8990147783251231, Train Precision: 0.8932038834951457\n",
      "Epoch 26: Val Loss: 0.8581640720367432, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 27: Train Loss: 0.2748447054853806, Train Accuracy: 0.9113300492610837, Train Precision: 0.9073170731707317\n",
      "Epoch 27: Val Loss: 0.8435226529836655, Val Accuracy: 0.58, Val Precision: 0.5625\n",
      "Epoch 28: Train Loss: 0.29515573439689785, Train Accuracy: 0.8916256157635468, Train Precision: 0.8955223880597015\n",
      "Epoch 28: Val Loss: 0.846837230026722, Val Accuracy: 0.6, Val Precision: 0.5757575757575758\n",
      "Epoch 29: Train Loss: 0.24564679654744956, Train Accuracy: 0.916256157635468, Train Precision: 0.9082125603864735\n",
      "Epoch 29: Val Loss: 0.9500545188784599, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 30: Train Loss: 0.22561223002580497, Train Accuracy: 0.9261083743842364, Train Precision: 0.9303482587064676\n",
      "Epoch 30: Val Loss: 1.0478069633245468, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 31: Train Loss: 0.2117495617041221, Train Accuracy: 0.9310344827586207, Train Precision: 0.9353233830845771\n",
      "Epoch 31: Val Loss: 1.0975552648305893, Val Accuracy: 0.64, Val Precision: 0.5897435897435898\n",
      "Epoch 32: Train Loss: 0.22867400428423515, Train Accuracy: 0.916256157635468, Train Precision: 0.9121951219512195\n",
      "Epoch 32: Val Loss: 1.1293903589248657, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 33: Train Loss: 0.18345834630040023, Train Accuracy: 0.9507389162561576, Train Precision: 0.9420289855072463\n",
      "Epoch 33: Val Loss: 1.146094650030136, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 34: Train Loss: 0.18813913945968336, Train Accuracy: 0.9408866995073891, Train Precision: 0.949748743718593\n",
      "Epoch 34: Val Loss: 1.1905687376856804, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 35: Train Loss: 0.1840170366832843, Train Accuracy: 0.9507389162561576, Train Precision: 0.9507389162561576\n",
      "Epoch 35: Val Loss: 1.1979315504431725, Val Accuracy: 0.58, Val Precision: 0.5588235294117647\n",
      "Epoch 36: Train Loss: 0.18590189043719035, Train Accuracy: 0.9334975369458128, Train Precision: 0.9356435643564357\n",
      "Epoch 36: Val Loss: 1.0962125808000565, Val Accuracy: 0.56, Val Precision: 0.5454545454545454\n",
      "Epoch 37: Train Loss: 0.1597195900976658, Train Accuracy: 0.9556650246305419, Train Precision: 0.964824120603015\n",
      "Epoch 37: Val Loss: 1.18754543364048, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 38: Train Loss: 0.15951063039784247, Train Accuracy: 0.9532019704433498, Train Precision: 0.9509803921568627\n",
      "Epoch 38: Val Loss: 1.3223042488098145, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 39: Train Loss: 0.13587540244826904, Train Accuracy: 0.9605911330049262, Train Precision: 0.9651741293532339\n",
      "Epoch 39: Val Loss: 1.273135244846344, Val Accuracy: 0.58, Val Precision: 0.5588235294117647\n",
      "Epoch 40: Train Loss: 0.17227126142153373, Train Accuracy: 0.9359605911330049, Train Precision: 0.927536231884058\n",
      "Epoch 40: Val Loss: 1.106234073638916, Val Accuracy: 0.56, Val Precision: 0.5454545454545454\n",
      "Epoch 41: Train Loss: 0.15087443819412819, Train Accuracy: 0.9532019704433498, Train Precision: 0.96\n",
      "Epoch 41: Val Loss: 1.3241641372442245, Val Accuracy: 0.58, Val Precision: 0.5588235294117647\n",
      "Epoch 42: Train Loss: 0.13173767308203074, Train Accuracy: 0.9605911330049262, Train Precision: 0.9605911330049262\n",
      "Epoch 42: Val Loss: 1.4005903154611588, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 43: Train Loss: 0.11098701349244668, Train Accuracy: 0.9753694581280788, Train Precision: 0.9800995024875622\n",
      "Epoch 43: Val Loss: 1.3930744528770447, Val Accuracy: 0.58, Val Precision: 0.5588235294117647\n",
      "Epoch 44: Train Loss: 0.1183326098208244, Train Accuracy: 0.9655172413793104, Train Precision: 0.9609756097560975\n",
      "Epoch 44: Val Loss: 1.3991710841655731, Val Accuracy: 0.58, Val Precision: 0.5588235294117647\n",
      "Epoch 45: Train Loss: 0.10914159322587344, Train Accuracy: 0.9630541871921182, Train Precision: 0.9795918367346939\n",
      "Epoch 45: Val Loss: 1.441173955798149, Val Accuracy: 0.64, Val Precision: 0.5945945945945946\n",
      "Epoch 46: Train Loss: 0.09717540586223969, Train Accuracy: 0.9753694581280788, Train Precision: 0.9753694581280788\n",
      "Epoch 46: Val Loss: 1.4286089688539505, Val Accuracy: 0.62, Val Precision: 0.5833333333333334\n",
      "Epoch 47: Train Loss: 0.1041119837990174, Train Accuracy: 0.9679802955665024, Train Precision: 0.9656862745098039\n",
      "Epoch 47: Val Loss: 1.4828841090202332, Val Accuracy: 0.62, Val Precision: 0.5833333333333334\n",
      "Epoch 48: Train Loss: 0.12189325948174183, Train Accuracy: 0.9630541871921182, Train Precision: 0.9607843137254902\n",
      "Epoch 48: Val Loss: 1.476311519742012, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 49: Train Loss: 0.1280024518760351, Train Accuracy: 0.9679802955665024, Train Precision: 0.9656862745098039\n",
      "Epoch 49: Val Loss: 1.520746573805809, Val Accuracy: 0.58, Val Precision: 0.5588235294117647\n",
      "Epoch 50: Train Loss: 0.08661694774547449, Train Accuracy: 0.9827586206896551, Train Precision: 0.9803921568627451\n",
      "Epoch 50: Val Loss: 1.4698143899440765, Val Accuracy: 0.58, Val Precision: 0.5588235294117647\n",
      "Epoch 51: Train Loss: 0.10255987003732187, Train Accuracy: 0.9679802955665024, Train Precision: 0.9702970297029703\n",
      "Epoch 51: Val Loss: 1.216644287109375, Val Accuracy: 0.62, Val Precision: 0.5833333333333334\n",
      "Epoch 52: Train Loss: 0.10348897756865391, Train Accuracy: 0.9679802955665024, Train Precision: 0.975\n",
      "Epoch 52: Val Loss: 1.2018844038248062, Val Accuracy: 0.62, Val Precision: 0.5833333333333334\n",
      "Epoch 53: Train Loss: 0.08464918421724668, Train Accuracy: 0.9729064039408867, Train Precision: 0.9615384615384616\n",
      "Epoch 53: Val Loss: 1.084180012345314, Val Accuracy: 0.6, Val Precision: 0.5757575757575758\n",
      "Epoch 54: Train Loss: 0.07690426657119623, Train Accuracy: 0.9827586206896551, Train Precision: 0.9851485148514851\n",
      "Epoch 54: Val Loss: 1.4974161088466644, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 55: Train Loss: 0.09356915033780612, Train Accuracy: 0.9753694581280788, Train Precision: 0.9753694581280788\n",
      "Epoch 55: Val Loss: 1.5016992092132568, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 56: Train Loss: 0.09628746902140287, Train Accuracy: 0.9753694581280788, Train Precision: 0.966183574879227\n",
      "Epoch 56: Val Loss: 1.2968186438083649, Val Accuracy: 0.58, Val Precision: 0.5625\n",
      "Epoch 57: Train Loss: 0.08409720902832654, Train Accuracy: 0.9729064039408867, Train Precision: 0.9705882352941176\n",
      "Epoch 57: Val Loss: 1.366778776049614, Val Accuracy: 0.56, Val Precision: 0.5454545454545454\n",
      "Epoch 58: Train Loss: 0.08367801973452935, Train Accuracy: 0.9802955665024631, Train Precision: 0.9802955665024631\n",
      "Epoch 58: Val Loss: 1.6962107568979263, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 59: Train Loss: 0.06144315212105329, Train Accuracy: 0.9827586206896551, Train Precision: 0.99\n",
      "Epoch 59: Val Loss: 1.7309995293617249, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 60: Train Loss: 0.09449632050326237, Train Accuracy: 0.9605911330049262, Train Precision: 0.9560975609756097\n",
      "Epoch 60: Val Loss: 1.771283894777298, Val Accuracy: 0.56, Val Precision: 0.5405405405405406\n",
      "Epoch 61: Train Loss: 0.09660319009652504, Train Accuracy: 0.9778325123152709, Train Precision: 0.9801980198019802\n",
      "Epoch 61: Val Loss: 1.7813915014266968, Val Accuracy: 0.56, Val Precision: 0.5405405405405406\n",
      "Epoch 62: Train Loss: 0.06970379752321886, Train Accuracy: 0.9778325123152709, Train Precision: 0.985\n",
      "Epoch 62: Val Loss: 1.7891127467155457, Val Accuracy: 0.58, Val Precision: 0.5526315789473685\n",
      "Epoch 63: Train Loss: 0.076681446391516, Train Accuracy: 0.9802955665024631, Train Precision: 0.9710144927536232\n",
      "Epoch 63: Val Loss: 1.7586132884025574, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 64: Train Loss: 0.05899796799684946, Train Accuracy: 0.9852216748768473, Train Precision: 0.9852216748768473\n",
      "Epoch 64: Val Loss: 1.7487813383340836, Val Accuracy: 0.62, Val Precision: 0.5789473684210527\n",
      "Epoch 65: Train Loss: 0.06704076766394652, Train Accuracy: 0.9827586206896551, Train Precision: 0.9851485148514851\n",
      "Epoch 65: Val Loss: 1.7578682750463486, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 66: Train Loss: 0.05619669698465329, Train Accuracy: 0.9901477832512315, Train Precision: 0.9950248756218906\n",
      "Epoch 66: Val Loss: 1.9511255025863647, Val Accuracy: 0.54, Val Precision: 0.5238095238095238\n",
      "Epoch 67: Train Loss: 0.08108722468694815, Train Accuracy: 0.9753694581280788, Train Precision: 0.9753694581280788\n",
      "Epoch 67: Val Loss: 1.763892412185669, Val Accuracy: 0.62, Val Precision: 0.5789473684210527\n",
      "Epoch 68: Train Loss: 0.06024048724569953, Train Accuracy: 0.9827586206896551, Train Precision: 0.9803921568627451\n",
      "Epoch 68: Val Loss: 1.692518413066864, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 69: Train Loss: 0.06744441189444982, Train Accuracy: 0.9778325123152709, Train Precision: 0.9801980198019802\n",
      "Epoch 69: Val Loss: 1.749846875667572, Val Accuracy: 0.6, Val Precision: 0.5714285714285714\n",
      "Epoch 70: Train Loss: 0.07914061822856848, Train Accuracy: 0.9679802955665024, Train Precision: 0.9656862745098039\n",
      "Epoch 70: Val Loss: 1.6689414530992508, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 71: Train Loss: 0.07897653491594471, Train Accuracy: 0.9802955665024631, Train Precision: 0.9850746268656716\n",
      "Epoch 71: Val Loss: 1.7528361082077026, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 72: Train Loss: 0.05436951179917042, Train Accuracy: 0.9802955665024631, Train Precision: 0.9850746268656716\n",
      "Epoch 72: Val Loss: 1.7799544036388397, Val Accuracy: 0.56, Val Precision: 0.5405405405405406\n",
      "Epoch 73: Train Loss: 0.06237303619631208, Train Accuracy: 0.9753694581280788, Train Precision: 0.9707317073170731\n",
      "Epoch 73: Val Loss: 1.6519624292850494, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 74: Train Loss: 0.030557255439746838, Train Accuracy: 0.9950738916256158, Train Precision: 0.9950738916256158\n",
      "Epoch 74: Val Loss: 1.6634569764137268, Val Accuracy: 0.62, Val Precision: 0.5789473684210527\n",
      "Epoch 75: Train Loss: 0.044546295064859666, Train Accuracy: 0.9852216748768473, Train Precision: 0.9900497512437811\n",
      "Epoch 75: Val Loss: 1.7506554275751114, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 76: Train Loss: 0.06433205288619949, Train Accuracy: 0.9802955665024631, Train Precision: 0.975609756097561\n",
      "Epoch 76: Val Loss: 1.5239185988903046, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 77: Train Loss: 0.04430785391909572, Train Accuracy: 0.9852216748768473, Train Precision: 0.9852216748768473\n",
      "Epoch 77: Val Loss: 1.6516970098018646, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 78: Train Loss: 0.033381460736004204, Train Accuracy: 0.9950738916256158, Train Precision: 0.9902439024390244\n",
      "Epoch 78: Val Loss: 1.7497163116931915, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 79: Train Loss: 0.029336682377526395, Train Accuracy: 0.9950738916256158, Train Precision: 0.9950738916256158\n",
      "Epoch 79: Val Loss: 1.7218179404735565, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 80: Train Loss: 0.01693399676766533, Train Accuracy: 1.0, Train Precision: 1.0\n",
      "Epoch 80: Val Loss: 1.8275182247161865, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 81: Train Loss: 0.03151376316180596, Train Accuracy: 0.9950738916256158, Train Precision: 0.9950738916256158\n",
      "Epoch 81: Val Loss: 1.4802067875862122, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 82: Train Loss: 0.058889552198636994, Train Accuracy: 0.9901477832512315, Train Precision: 0.9950248756218906\n",
      "Epoch 82: Val Loss: 1.9033012390136719, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 83: Train Loss: 0.04375867162329646, Train Accuracy: 0.9876847290640394, Train Precision: 0.9900990099009901\n",
      "Epoch 83: Val Loss: 2.0088901668787003, Val Accuracy: 0.54, Val Precision: 0.5277777777777778\n",
      "Epoch 84: Train Loss: 0.028261301573365927, Train Accuracy: 0.9901477832512315, Train Precision: 0.9901477832512315\n",
      "Epoch 84: Val Loss: 1.8285907804965973, Val Accuracy: 0.58, Val Precision: 0.5588235294117647\n",
      "Epoch 85: Train Loss: 0.027922431651789408, Train Accuracy: 0.9926108374384236, Train Precision: 1.0\n",
      "Epoch 85: Val Loss: 2.0068018436431885, Val Accuracy: 0.6, Val Precision: 0.5675675675675675\n",
      "Epoch 86: Train Loss: 0.049575422066622056, Train Accuracy: 0.9852216748768473, Train Precision: 0.9852216748768473\n",
      "Epoch 86: Val Loss: 1.9813207685947418, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 87: Train Loss: 0.038780442582300075, Train Accuracy: 0.9901477832512315, Train Precision: 0.9901477832512315\n",
      "Epoch 87: Val Loss: 1.917018324136734, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 88: Train Loss: 0.038331057159946516, Train Accuracy: 0.9926108374384236, Train Precision: 0.995049504950495\n",
      "Epoch 88: Val Loss: 2.0205723494291306, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 89: Train Loss: 0.03780518611893058, Train Accuracy: 0.9876847290640394, Train Precision: 0.9852941176470589\n",
      "Epoch 89: Val Loss: 2.0724215507507324, Val Accuracy: 0.56, Val Precision: 0.5405405405405406\n",
      "Epoch 90: Train Loss: 0.04655711288348986, Train Accuracy: 0.9901477832512315, Train Precision: 0.9853658536585366\n",
      "Epoch 90: Val Loss: 1.7982456684112549, Val Accuracy: 0.6, Val Precision: 0.5757575757575758\n",
      "Epoch 91: Train Loss: 0.04810254626835768, Train Accuracy: 0.9827586206896551, Train Precision: 0.9803921568627451\n",
      "Epoch 91: Val Loss: 1.979491800069809, Val Accuracy: 0.58, Val Precision: 0.5555555555555556\n",
      "Epoch 92: Train Loss: 0.03871837698926146, Train Accuracy: 0.9852216748768473, Train Precision: 0.9900497512437811\n",
      "Epoch 92: Val Loss: 2.0842630565166473, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 93: Train Loss: 0.02328832386634671, Train Accuracy: 0.9975369458128078, Train Precision: 0.9950980392156863\n",
      "Epoch 93: Val Loss: 2.102822571992874, Val Accuracy: 0.54, Val Precision: 0.5277777777777778\n",
      "Epoch 94: Train Loss: 0.027396663468187817, Train Accuracy: 0.9950738916256158, Train Precision: 0.9950738916256158\n",
      "Epoch 94: Val Loss: 1.565745733678341, Val Accuracy: 0.56, Val Precision: 0.5428571428571428\n",
      "Epoch 95: Train Loss: 0.03360594355931076, Train Accuracy: 0.9950738916256158, Train Precision: 1.0\n",
      "Epoch 95: Val Loss: 2.170832872390747, Val Accuracy: 0.54, Val Precision: 0.5277777777777778\n",
      "Epoch 96: Train Loss: 0.03078601253218949, Train Accuracy: 0.9926108374384236, Train Precision: 0.9901960784313726\n",
      "Epoch 96: Val Loss: 1.5164686609059572, Val Accuracy: 0.54, Val Precision: 0.53125\n",
      "Epoch 97: Train Loss: 0.0168411096629615, Train Accuracy: 1.0, Train Precision: 1.0\n",
      "Epoch 97: Val Loss: 1.5828474797308445, Val Accuracy: 0.54, Val Precision: 0.5294117647058824\n",
      "Epoch 98: Train Loss: 0.028845944710505698, Train Accuracy: 0.9950738916256158, Train Precision: 0.9950738916256158\n",
      "Epoch 98: Val Loss: 1.9810980260372162, Val Accuracy: 0.56, Val Precision: 0.5405405405405406\n",
      "Epoch 99: Train Loss: 0.0126335766309729, Train Accuracy: 0.9975369458128078, Train Precision: 1.0\n",
      "Epoch 99: Val Loss: 1.9177420735359192, Val Accuracy: 0.56, Val Precision: 0.5405405405405406\n",
      "Epoch 100: Train Loss: 0.02705465703128049, Train Accuracy: 0.9901477832512315, Train Precision: 0.9901477832512315\n",
      "Epoch 100: Val Loss: 1.7019798159599304, Val Accuracy: 0.56, Val Precision: 0.5405405405405406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data loading and preparation \n",
    "features_columns = ['Molecular Weight', 'LogP', 'Number of Atoms',\n",
    "       'Number of Bonds', 'Number of Rings', 'Rotatable Bonds Count',\n",
    "       'Hydrogen Bond Donors', 'Hydrogen Bond Acceptors',\n",
    "       'Number of Stereocenters', 'Topological Polar Surface Area (TPSA)']\n",
    "# labels = data['Results'].values\n",
    "\n",
    "  \n",
    "\n",
    "train_data = pd.read_csv('/home/parsa/smiles_classification/training_w_features.csv').sample(frac=1)\n",
    "val_data = pd.read_csv('/home/parsa/smiles_classification/validation_w_features.csv').sample(frac=1)\n",
    "\n",
    "X_train, X_val = train_data[features_columns].values, val_data[features_columns].values\n",
    "y_train, y_val = train_data['Results'].values, val_data['RESULT'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('DeepChem/ChemBERTa-77M-MLM')\n",
    "train_encodings = tokenizer(list(train_data['SMILES']), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(list(val_data['SMILES']), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "train_dataset = MoleculeDataset(train_encodings, X_train_scaled, y_train)\n",
    "val_dataset = MoleculeDataset(val_encodings, X_val_scaled, y_val)\n",
    "\n",
    "# Set up DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = ChemBERTaWithFeatures('DeepChem/ChemBERTa-77M-MLM', feature_dim=10).to(device)\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        features = batch['features'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, features)\n",
    "        loss = loss_function(outputs, labels.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "        all_preds.extend(outputs.detach().cpu().numpy())\n",
    "        all_labels.extend(labels.detach().cpu().numpy())\n",
    "    \n",
    "    train_accuracy, train_precision = compute_metrics(torch.tensor(all_preds), torch.tensor(all_labels))\n",
    "    # wandb.log({\"train_loss\": total_loss / len(train_loader), \"train_accuracy\": train_accuracy, \"train_precision\": train_precision})\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask, features).squeeze(1)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            all_preds.extend(outputs.detach().cpu().numpy())\n",
    "            all_labels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "    val_accuracy, val_precision = compute_metrics(torch.tensor(all_preds), torch.tensor(all_labels))\n",
    "    # wandb.log({\"val_loss\": val_loss / len(val_loader), \"val_accuracy\": val_accuracy, \"val_precision\": val_precision})\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {total_loss / len(train_loader)}, Train Accuracy: {train_accuracy}, Train Precision: {train_precision}\")\n",
    "    print(f\"Epoch {epoch+1}: Val Loss: {val_loss / len(val_loader)}, Val Accuracy: {val_accuracy}, Val Precision: {val_precision}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9494809210300446\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the validation set\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        features = batch['features'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask, features)\n",
    "        loss = loss_function(outputs, labels.unsqueeze(1))\n",
    "        val_loss += loss.item()\n",
    "    # wandb.log({\"val_loss\": val_loss / len(val_loader)})\n",
    "\n",
    "print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
